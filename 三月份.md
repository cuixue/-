# 我的三月份论文

## 阅读理解
【1】Deep mind 组在这篇论文中提供了两个公开的阅读理解数据集。同时考虑到一些命名实体不通过理解文章也能判断出来，此文提出了entity replacement 和 
 permutation. 这篇论文中提出了两种模型。第一种模型为attentive reader 即在阅读每一个词的时候都给其对于query的一个权重。另一种策略是对于query中的
 每一个词都去阅读一次文章。类比于人的话，在我们阅读的时候，一般不会阅读到问题的每个词的时候，都去阅读一次原文的。但是最终的结果。两个模型效果相当。
 attentive reader 的效果可能更好些。
      
      [Teaching Machines to Read and Comprehend(Nips15)]

【2】这篇论文是facebook AI的文章。类比于图像这种高级的信息由低级信息构成的层级学习关系。学习vgg构造层级结构，学习resnet加了shortcut.贡献可能就是把文本利用小的卷积核但是特别深的网络做work.这是一篇文本分类的文章。受限于文本的类别太少...

      [Very Deep Convolutional Networks for Text Classification(arxiv17)]
 
【3】 文本是由句子构成的，句子是由单词构成的. 这样,构成了层级关系
    
      [Hierarchical Attention Networks for Document Classification(NAACL16)]
      
【4】 
